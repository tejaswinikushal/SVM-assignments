{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a8b3b10",
   "metadata": {},
   "source": [
    "#### Q1. What is the mathematical formula for a linear SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4e0f2e",
   "metadata": {},
   "source": [
    "f(x)=sign(w⋅x+b)\n",
    "\n",
    "Here,\n",
    "\n",
    "w is the weight vector perpendicular to the hyperplane, \n",
    "\n",
    "x is the input feature vector, and b is the bias term. The sign function ensures that the output is either -1 or 1, corresponding to the two classes in a binary classification problem. The parameters w and b are determined during the training process to find the optimal hyperplane that maximally separates the data points of different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab774d",
   "metadata": {},
   "source": [
    "#### Q2. What is the objective function of a linear SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fd423c",
   "metadata": {},
   "source": [
    "The objective function of a linear Support Vector Machine (SVM) involves finding the parameters w and b(bar) that define the hyperplane, while maximizing the margin between the two classes. The objective function for a linear SVM can be expressed as follows:\n",
    "\n",
    "Minimize( (1/2) ∥w∥**2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c739a264",
   "metadata": {},
   "source": [
    "#### Q3. What is the kernel trick in SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feac5dfe",
   "metadata": {},
   "source": [
    "The kernel trick is a technique used in Support Vector Machines (SVMs) to implicitly transform input data into a higher-dimensional space without explicitly computing the transformation. In traditional SVMs, a linear kernel is often used, which works well for linearly separable data. However, when the data is not linearly separable in the original feature space, the kernel trick allows SVMs to learn complex, non-linear decision boundaries by implicitly mapping the input data to a higher-dimensional space.\n",
    "\n",
    "The general idea behind the kernel trick is to introduce a kernel function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1868d2e",
   "metadata": {},
   "source": [
    "#### Q4. What is the role of support vectors in SVM Explain with example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7759349",
   "metadata": {},
   "source": [
    "Support vectors play a crucial role in Support Vector Machines (SVMs). In SVM, the objective is to find a hyperplane that maximally separates different classes in the feature space. Support vectors are the data points that are most important in determining the position and orientation of the hyperplane.\n",
    "\n",
    "EXAMPLE:\n",
    "\n",
    "Class -1:\n",
    "\n",
    "Point A: (1,2)\n",
    "\n",
    "Point B: (2,3)\n",
    "\n",
    "Class 1:\n",
    "\n",
    "Point C: (−1,−1)\n",
    "\n",
    "Point D:(−2,−3)\n",
    "\n",
    "The linear SVM aims to find a hyperplane (a line in this case) that best separates the two classes.\n",
    "\n",
    "After training, the SVM finds the hyperplane 2x1+3x2−6=0.\n",
    "Support vectors are the points on or closest to the margin:\n",
    "\n",
    "Point A: (1,2)\n",
    "Point B: (2,3)\n",
    "Point C: (−1,−1)\n",
    "These support vectors are crucial in defining the hyperplane and maximizing the margin between the classes.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f941f696",
   "metadata": {},
   "source": [
    "#### Q5. Illustrate with examples and graphs of Hyperplane, Marginal plane, Soft margin and Hard margin in SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78baa24",
   "metadata": {},
   "source": [
    "1. Hyperplane:\n",
    "A hyperplane is a decision boundary that separates different classes in a linear SVM. In a 2D space, a hyperplane is a line, and in 3D, it's a plane. The equation for a hyperplane in a 2D space is w1x1+w2x2+b=0.\n",
    "\n",
    "Example:\n",
    "\n",
    "Consider a 2D space with two classes (blue and red). The hyperplane 2x1−3x2+5=0 is the decision boundary.\n",
    "\n",
    "2. Marginal Plane:\n",
    "The marginal plane is a plane parallel to the hyperplane but at a certain distance (margin) from it. The margin is the distance between the hyperplane and the nearest data point from either class.\n",
    "\n",
    "Example:\n",
    "\n",
    "Using the same example, the marginal planes are parallel to the hyperplane, defining the margin. Points A, B, and C are the support vectors contributing to the margin.\n",
    "\n",
    "\n",
    "3. Soft Margin:\n",
    "In real-world scenarios, data may not be perfectly separable. The soft margin allows for some misclassification to achieve a balance between maximizing the margin and minimizing errors. This is useful when dealing with noisy or overlapping data.\n",
    "\n",
    "Example:\n",
    "\n",
    "Consider a case with noisy data. The soft margin allows for a few misclassifications, represented by the dotted lines.\n",
    "\n",
    "\n",
    "4. Hard Margin:\n",
    "In contrast, a hard margin SVM aims to perfectly separate classes with no misclassifications. This is suitable when the data is well-behaved and noise-free.\n",
    "\n",
    "Example:\n",
    "\n",
    "Assuming perfectly separable data, the hard margin SVM seeks to find a hyperplane with no misclassifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8401ebaa",
   "metadata": {},
   "source": [
    "#### Q6. SVM Implementation through Iris dataset.\n",
    "#### ~ Load the iris dataset from the scikit-learn library and split it into a training set and a testing setl\n",
    "#### ~ Train a linear SVM classifier on the training set and predict the labels for the testing setl\n",
    "#### ~ Compute the accuracy of the model on the testing setl\n",
    "#### ~ Plot the decision boundaries of the trained model using two of the featuresl\n",
    "#### ~ Try different values of the regularisation parameter C and see how it affects the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "887278e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b067f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8675b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82258e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_classifier=SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e3a8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e88e36e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=svm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa0bc96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b042d7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d91a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Try different values of the regularisation parameter C and see how it affects the performance of the model.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid={'C':[0.001,0.01,0.1,1,10,100,1000]}\n",
    "grid=GridSearchCV(svm_classifier,param_grid,cv=5,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea9107c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)\n",
    "y_pred=grid.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b13e7d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b07dd1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc970b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
