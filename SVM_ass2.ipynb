{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00f3a860",
   "metadata": {},
   "source": [
    "#### Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e309f662",
   "metadata": {},
   "source": [
    " kernel functions play a crucial role in non-linear models, particularly in Support Vector Machines (SVMs). Polynomial functions are a type of kernel function used in SVMs and other algorithms.\n",
    " \n",
    "#### Kernel Functions:\n",
    "            Kernel functions are mathematical functions that take in two input vectors and return a scalar. In the context of machine learning, these vectors typically represent data points in a high-dimensional space.\n",
    "            \n",
    "Kernels are often used to implicitly map input data into a higher-dimensional space, making it easier to find complex, non-linear patterns in the data.\n",
    " \n",
    "#### Polynomial Kernel Function:\n",
    "\n",
    "The polynomial kernel is a specific type of kernel function commonly used in SVMs. It is defined as K(x,y)=(x⋅y+c)^d, where x and y are input vectors,c is a constant, and d is the degree of the polynomial.\n",
    "The polynomial kernel allows SVMs to capture non-linear decision boundaries by introducing polynomial terms in the feature space.\n",
    "\n",
    "#### Relationship:\n",
    "\n",
    "Polynomial functions are a type of kernel function. When we talk about using a polynomial kernel in a machine learning model, we are essentially using a polynomial function to compute the similarity between pairs of data points.\n",
    "The polynomial kernel is a specific instance of a more general concept of kernel functions. It uses polynomial terms to capture non-linear relationships in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979997b2",
   "metadata": {},
   "source": [
    "#### Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f727c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b4ecb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()\n",
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea104979",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d35607bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC(kernel='poly',degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "241cce3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5aa9434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=svc.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb94dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32b80df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the testing set: 97.37%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on the testing set: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0baeedb",
   "metadata": {},
   "source": [
    "#### Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc49b8c",
   "metadata": {},
   "source": [
    "#### Here's how increasing the value of epsilon can affect the number of support vectors in SVR:\n",
    "\n",
    "Wider Tube:\n",
    "\n",
    "When you increase the value of epsilon, you are essentially widening the epsilon-insensitive tube. This means that data points can fall within a larger range around the regression line without contributing to the loss function.\n",
    "Increased Tolerance:\n",
    "\n",
    "Larger epsilon values lead to a higher tolerance for errors. Data points can be farther away from the predicted values within the tube without being considered as errors or support vectors.\n",
    "Fewer Support Vectors:\n",
    "\n",
    "With a wider epsilon-insensitive tube, fewer data points are likely to fall outside the tube and contribute to the support vectors. The SVR model becomes more tolerant of deviations, and only the points outside the wider tube contribute to the support vectors.\n",
    "Smoothing Effect:\n",
    "\n",
    "A larger epsilon tends to result in a smoother regression function. It allows the model to focus on capturing the general trend rather than fitting the training data precisely.\n",
    "Trade-off with Model Complexity:\n",
    "\n",
    "Increasing epsilon introduces a trade-off between model complexity and precision. A larger epsilon results in a simpler model with fewer support vectors but may sacrifice precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c44371",
   "metadata": {},
   "source": [
    "#### Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672173f3",
   "metadata": {},
   "source": [
    "#### Kernel Function:\n",
    "\n",
    "Purpose: Determines the type of mapping used to transform the input data into a higher-dimensional space.\n",
    "\n",
    "Example:Use a linear kernel (kernel='linear') for linear relationships.\n",
    "\n",
    "Use a radial basis function (RBF) kernel (kernel='rbf') for capturing non-linear relationships.\n",
    "\n",
    "Decision:\n",
    "Choose based on the underlying pattern in your data.\n",
    "#### C Parameter (Regularization):\n",
    "\n",
    "Purpose: Controls the trade-off between fitting the training data well and having a smooth decision boundary.\n",
    "\n",
    "Example:\n",
    "\n",
    "Higher C: More emphasis on fitting the training data precisely (may lead to overfitting).\n",
    "\n",
    "Lower C: Smoother decision boundary, more tolerance for errors (may lead to underfitting).\n",
    "\n",
    "Decision:\n",
    "Increase C for complex datasets or when you want a closer fit.\n",
    "Decrease C for simpler models with more tolerance for errors.\n",
    "\n",
    "#### Epsilon Parameter:\n",
    "\n",
    "Purpose: Defines the width of the epsilon-insensitive tube around the regression line.\n",
    "\n",
    "Example:\n",
    "\n",
    "Larger epsilon: Wider tube, more tolerance for deviations.\n",
    "\n",
    "Smaller epsilon: Narrower tube, less tolerance for deviations.\n",
    "\n",
    "Decision:\n",
    "Increase epsilon for a more forgiving model that allows larger errors.\n",
    "Decrease epsilon for a stricter model that penalizes smaller errors.\n",
    "\n",
    "#### Gamma Parameter:\n",
    "\n",
    "Purpose: Influences the shape and reach of the decision boundary, especially in the case of RBF kernel.\n",
    "\n",
    "Example:\n",
    "Higher gamma: Narrower decision boundary, more sensitivity to local patterns.\n",
    "\n",
    "Lower gamma: Smoother decision boundary, more sensitivity to global patterns.\n",
    "\n",
    "Decision:\n",
    "Increase gamma for complex, non-linear patterns.\n",
    "Decrease gamma for simpler, smoother decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3e08b2",
   "metadata": {},
   "source": [
    "#### Q5. Assignment:\n",
    "#### Import the necessary libraries and load the dataset\n",
    "#### Split the dataset into training and testing set\n",
    "#### Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "#### Create an instance of the SVC classifier and train it on the training data\n",
    "#### use the trained classifier to predict the labels of the testing data\n",
    "#### Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy, precision, recall, F1-score)\n",
    "#### Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to improve its performance\n",
    "#### Train the tuned classifier on the entire dataset\n",
    "#### Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a753a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9825\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "\n",
      "Best Hyperparameters: {'C': 0.1, 'gamma': 0.001, 'kernel': 'linear'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9824561403508771"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the SVC classifier\n",
    "svc_classifier = SVC()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svc_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the labels of the testing data\n",
    "y_pred = svc_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('\\nClassification Report:')\n",
    "print(classification_rep)\n",
    "\n",
    "# Tune hyperparameters using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1], 'kernel': ['linear', 'rbf']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print('\\nBest Hyperparameters:', best_params)\n",
    "\n",
    "# Create a tuned SVC classifier with the best hyperparameters\n",
    "tuned_svc_classifier = SVC(**best_params)\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "tuned_svc_classifier.fit(X, y)\n",
    "\n",
    "# Save the trained classifier to a file for future use\n",
    "joblib.dump(tuned_svc_classifier, 'tuned_svc_classifier.joblib')\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d88255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
